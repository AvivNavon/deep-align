{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a5ed35",
   "metadata": {
    "id": "91a5ed35",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MNIST MLP Classifiers\n",
    "\n",
    "A quick start notebook for performing an alignment on MNIST MLPs.\n",
    "\n",
    "**Make sure you change the runtime type to GPU before starting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0a94e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17d0a94e",
    "outputId": "f4711831-0ac0-4f0f-a4fc-f3f300389cba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If not installed already, please install deep-align and all its dependencies.\n",
    "! git clone https://github.com/AvivNavon/deep-align.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clioeDU4RHME",
   "metadata": {
    "id": "clioeDU4RHME",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cd deep-align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AqLR4erlS8XK",
   "metadata": {
    "id": "AqLR4erlS8XK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tZX7UueTUREC",
   "metadata": {
    "id": "tZX7UueTUREC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get Data\n",
    "Next, we download the MNIST MLPs dataset and place it in `dataset/mnist_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "QKYprAdjU3bi",
   "metadata": {
    "id": "QKYprAdjU3bi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QHJ2ZlzibwOo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHJ2ZlzibwOo",
    "outputId": "d502ae9a-ddda-48f4-d167-5df0ffb12e97",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/sh/56pakaxe58z29mq/AABtWNkRYroLYe_cE3c90DXVa?dl=0 -O data_files.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vWNSiPEqb9un",
   "metadata": {
    "id": "vWNSiPEqb9un",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!unzip -q mnist_classifiers.zip -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1EcAWmJBaeMY",
   "metadata": {
    "id": "1EcAWmJBaeMY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c520241-310a-4db1-9c6b-6c6382018771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import trange\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from experiments.utils.data.generate_splits import generate_splits\n",
    "\n",
    "from deepalign.losses.mlp_losses import calc_lmc_loss, calc_recon_loss, calc_gt_perm_loss\n",
    "from deepalign.utils import extract_pred\n",
    "from experiments.utils import (\n",
    "    common_parser, count_parameters, get_device, set_logger, set_seed, str2bool,\n",
    ")\n",
    "from experiments.utils.data import MultiViewMatchingBatch, MatchingModelsDataset\n",
    "from deepalign.sinkhorn import matching\n",
    "from deepalign import DWSMatching\n",
    "from experiments.utils.data.image_data import get_mnist_dataloaders\n",
    "\n",
    "set_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2b61d",
   "metadata": {
    "id": "bcc2b61d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate Data Splits\n",
    "Next, create the data split, using a subset of the extracted dataset. We will use 1000 models for train and 100 for val/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd035dc",
   "metadata": {
    "id": "dbd035dc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 22:04:51,787 - root - INFO - train size: 1000, val size: 100, test size: 100\n"
     ]
    }
   ],
   "source": [
    "# create dataset splits (train/val/test)\n",
    "generate_splits(data_root=\"dataset/mnist_models\", save_path=\"dataset/splits.json\", test_size=100, val_size=100, max_models=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a1c45",
   "metadata": {
    "id": "cb3a1c45",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MLP Dataset\n",
    "\n",
    "We create MLP Datasets and Dataloaders.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81e462e",
   "metadata": {
    "id": "c81e462e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = \"dataset/splits.json\"\n",
    "batch_size = 8\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ef4753-9054-42a6-87c4-ef47aa44f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MatchingModelsDataset(\n",
    "        path=path,\n",
    "        split=\"train\",\n",
    "    )\n",
    "val_set = MatchingModelsDataset(\n",
    "    path=path,\n",
    "    split=\"val\",\n",
    ")\n",
    "test_set = MatchingModelsDataset(\n",
    "    path=path,\n",
    "    split=\"test\",\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1842df-462d-4325-a103-3de8a823c0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weights_view_0', 'biases_view_0', 'weights_view_1', 'biases_view_1', 'perm_weights_view_0', 'perm_biases_view_0', 'perm_weights_view_1', 'perm_biases_view_1', 'perms_view_0', 'perms_view_1'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch.as_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202e883d-ca76-4946-86e8-ef84756a81e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 22:46:53,094 - root - INFO - train size 1000, val size 100, test size 100\n",
      "2024-05-03 22:46:53,097 - root - INFO - weight shapes: (torch.Size([784, 128]), torch.Size([128, 128]), torch.Size([128, 128]), torch.Size([128, 10])), bias shapes: (torch.Size([128]), torch.Size([128]), torch.Size([128]), torch.Size([10]))\n"
     ]
    }
   ],
   "source": [
    "logging.info(\n",
    "    f\"train size {len(train_set)}, \"\n",
    "    f\"val size {len(val_set)}, \"\n",
    "    f\"test size {len(test_set)}\"\n",
    ")\n",
    "\n",
    "weight_shapes, bias_shapes = batch.get_weight_shapes()\n",
    "\n",
    "logging.info(f\"weight shapes: {weight_shapes}, bias shapes: {bias_shapes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad1393",
   "metadata": {
    "id": "e5ad1393",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Image Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdc211cc-52bf-48c0-9cd9-d54c3f9829c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_path = \"datasets/MNIST\"\n",
    "image_batch_size = 12\n",
    "allow_download = True  # allow downloading MNIST\n",
    "image_flatten_size = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eff36a4-0d75-438d-be40-7b2444f4aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_loader, val_image_loader, test_image_loader = get_mnist_dataloaders(\n",
    "    image_data_path, batch_size=image_batch_size, allow_download=allow_download\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d130ca34",
   "metadata": {
    "id": "d130ca34",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialize DWSNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47ed3d5",
   "metadata": {
    "id": "e47ed3d5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 22:46:53,149 - root - INFO - device = cpu\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = get_device()\n",
    "logging.info(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d0ee8a-d4d4-4276-9009-70cc0734df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    hidden_dim=64\n",
    "    n_hidden=4\n",
    "    output_features=128\n",
    "    input_dim_downsample=8\n",
    "    add_bn=True\n",
    "    diagonal=True\n",
    "    # loss weights\n",
    "    supervised_loss_weight=1 \n",
    "    recon_loss_weight=1\n",
    "    add_task_loss=True\n",
    "    add_l2_loss=True\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716b620c",
   "metadata": {
    "id": "716b620c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 22:46:53,722 - root - INFO - number of parameters: 31873905\n"
     ]
    }
   ],
   "source": [
    "model = DWSMatching(\n",
    "        weight_shapes=weight_shapes,\n",
    "        bias_shapes=bias_shapes,\n",
    "        input_features=1,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        n_hidden=args.n_hidden,\n",
    "        output_features=args.output_features,\n",
    "        input_dim_downsample=args.input_dim_downsample,\n",
    "        bn=args.add_bn,\n",
    "        diagonal=args.diagonal,\n",
    "    ).to(device)\n",
    "\n",
    "logging.info(f\"number of parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e429cc7",
   "metadata": {
    "id": "6e429cc7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caa7571a",
   "metadata": {
    "id": "caa7571a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, image_loader, add_task_loss=True, add_l2_loss=True):\n",
    "    model.eval()\n",
    "\n",
    "    perm_loss = 0.0\n",
    "    recon_loss = 0.\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    predicted, gt = [], []\n",
    "    recon_losses, baseline_losses, hard_recon_losses, sink_ours_losses, sink_random_losses = [], [], [], [], []\n",
    "    for j, batch in enumerate(loader):\n",
    "        image_batch = next(iter(image_loader))\n",
    "        image_batch = tuple(t.to(device) for t in image_batch)\n",
    "        batch: MultiViewMatchingBatch = batch.to(device)\n",
    "\n",
    "        input_0 = (batch.weights_view_0, batch.biases_view_0)\n",
    "        input_1 = (batch.weights_view_1, batch.biases_view_1)\n",
    "        perm_input_0 = (batch.perm_weights_view_0, batch.perm_biases_view_0)\n",
    "\n",
    "        out_0 = model(input_0)\n",
    "        out_1 = model(input_1)\n",
    "        perm_out_0 = model(perm_input_0)\n",
    "\n",
    "        pred_matrices_perm_0 = extract_pred(\n",
    "            out_0,\n",
    "            perm_out_0,\n",
    "        )\n",
    "\n",
    "        pred_matrices = extract_pred(\n",
    "            out_0,\n",
    "            out_1,\n",
    "        )\n",
    "\n",
    "        # loss from GT permutations\n",
    "        curr_gt_loss = calc_gt_perm_loss(\n",
    "            pred_matrices_perm_0, batch.perms_view_0, device=device\n",
    "        )\n",
    "\n",
    "        # reconstruction loss\n",
    "        curr_recon_loss = calc_recon_loss(\n",
    "            pred_matrices,\n",
    "            input_0,\n",
    "            input_1,\n",
    "            image_batch=image_batch,\n",
    "            sinkhorn_project=True,\n",
    "            add_task_loss=add_task_loss,\n",
    "            add_l2_loss=add_l2_loss,\n",
    "            alpha=0.5,\n",
    "            eval_mode=True,\n",
    "            device=device,\n",
    "            image_flatten_size=image_flatten_size,\n",
    "        )\n",
    "\n",
    "        # reconstruction loss and images\n",
    "        results = calc_lmc_loss(\n",
    "            pred_matrices,\n",
    "            input_0,\n",
    "            input_1,\n",
    "            image_batch=image_batch,\n",
    "            sinkhorn_project=True,\n",
    "            device=device,\n",
    "            image_flatten_size=image_flatten_size,\n",
    "        )\n",
    "\n",
    "        recon_losses.append(results[\"soft\"][\"losses\"])\n",
    "        hard_recon_losses.append(results[\"hard\"][\"losses\"])\n",
    "        baseline_losses.append(results[\"no_alignment\"][\"losses\"])\n",
    "\n",
    "        perm_loss += curr_gt_loss.item()\n",
    "        recon_loss += curr_recon_loss.item()\n",
    "\n",
    "        curr_correct = 0.\n",
    "        curr_gts = []\n",
    "        curr_preds = []\n",
    "\n",
    "        for pred, gt_perm in zip(pred_matrices_perm_0, batch.perms_view_0):\n",
    "            pred = matching(pred).to(device)\n",
    "            curr_correct += ((pred.argmax(1)).eq(gt_perm) * 1.0).mean().item()\n",
    "            curr_preds.append(pred.argmax(1).reshape(-1))\n",
    "            curr_gts.append(gt_perm.reshape(-1))\n",
    "\n",
    "        total += 1\n",
    "        correct += (curr_correct / len(pred_matrices_perm_0))\n",
    "        predicted.extend(curr_preds)\n",
    "        gt.extend(curr_gts)\n",
    "\n",
    "    predicted = torch.cat(predicted).int()\n",
    "    gt = torch.cat(gt).int()\n",
    "\n",
    "    avg_loss = perm_loss / total\n",
    "    avg_acc = correct / total\n",
    "    recon_loss = recon_loss / total\n",
    "\n",
    "    f1 = f1_score(predicted.cpu().detach().numpy(), gt.cpu().detach().numpy(), average=\"macro\")\n",
    "\n",
    "    # LMC losses\n",
    "    lmc_losses = dict(\n",
    "        soft_alignment=np.stack(recon_losses).mean(0),  # NOTE: this is the soft alignment loss.\n",
    "        no_alignment=np.stack(baseline_losses).mean(0),\n",
    "        alignment=np.stack(hard_recon_losses).mean(0),\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        avg_loss=avg_loss,\n",
    "        avg_acc=avg_acc,\n",
    "        recon_loss=recon_loss,\n",
    "        predicted=predicted,\n",
    "        gt=gt,\n",
    "        f1=f1,\n",
    "        lmc_losses=lmc_losses,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e1421",
   "metadata": {
    "id": "5a2e1421",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a38d25",
   "metadata": {
    "id": "e0a38d25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5af6b6d",
   "metadata": {
    "id": "a5af6b6d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5  # doing just 5 epochs here, in the paper we do 100 on a larger train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1114e",
   "metadata": {
    "id": "8fa1114e",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_iter = trange(epochs)\n",
    "for epoch in epoch_iter:\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch: MultiViewMatchingBatch = batch.to(device)\n",
    "        image_batch = next(iter(train_image_loader))\n",
    "        image_batch = tuple(t.to(device) for t in image_batch)\n",
    "\n",
    "        input_0 = (batch.weights_view_0, batch.biases_view_0)\n",
    "        input_1 = (batch.weights_view_1, batch.biases_view_1)\n",
    "        perm_input_0 = (batch.perm_weights_view_0, batch.perm_biases_view_0)\n",
    "\n",
    "        out_0 = model(input_0)\n",
    "        out_1 = model(input_1)\n",
    "        perm_out_0 = model(perm_input_0)\n",
    "\n",
    "        pred_matrices_perm_0 = extract_pred(\n",
    "            out_0,\n",
    "            perm_out_0,\n",
    "        )\n",
    "\n",
    "        pred_matrices = extract_pred(\n",
    "            out_0,\n",
    "            out_1,\n",
    "        )\n",
    "\n",
    "        # loss from GT permutations\n",
    "        gt_perm_loss = calc_gt_perm_loss(\n",
    "            pred_matrices_perm_0, batch.perms_view_0, device=device\n",
    "        )\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = calc_recon_loss(\n",
    "            pred_matrices,\n",
    "            input_0,\n",
    "            input_1,\n",
    "            image_batch=image_batch,\n",
    "            sinkhorn_project=True,   # if we perms are already bi-stochastic we don't need to do anything\n",
    "            add_task_loss=args.add_task_loss,\n",
    "            add_l2_loss=args.add_l2_loss,\n",
    "            device=device,\n",
    "            image_flatten_size=image_flatten_size,\n",
    "        )\n",
    "\n",
    "        loss = gt_perm_loss * args.supervised_loss_weight + recon_loss * args.recon_loss_weight\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_iter.set_description(\n",
    "            f\"[{epoch} {i+1}], train loss: {loss.item():.3f}, recon loss: {recon_loss:.3f}, supervised loss: {gt_perm_loss:.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a436be-7f5e-4fb0-a5b6-efbdd46fd3c3",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad939a8e-cfd9-4adc-9498-8f1919380675",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_dict = evaluate(\n",
    "    model, test_loader, image_loader=test_image_loader,\n",
    "    add_task_loss=args.add_task_loss, add_l2_loss=args.add_l2_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014bff41-894f-43c6-8096-3e67d1f8fe07",
   "metadata": {},
   "source": [
    "## Plot LMC Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f26a9-111d-4330-a089-5f741d40356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0.0, 1.0, len(test_loss_dict[\"lmc_losses\"][\"alignment\"])).numpy().tolist()\n",
    "for k, v in test_loss_dict[\"lmc_losses\"].items():\n",
    "    plt.plot(x, v, label=k)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "deep-align",
   "language": "python",
   "name": "deep-align"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
